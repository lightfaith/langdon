#!/usr/bin/python3
"""
This script takes filename as an argument and tries every known
cryptanalysis method on it.
"""

import subprocess
import sys
import base64
import threading
import re
import math
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker

"""
Standard functions
"""
def debug(*args):
    if debug_flag:
        print('\033[90m[.]', *args, '\033[0m')

def run_command(command):
    p = subprocess.Popen(command, 
                         shell=True, 
                         stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE)
    (out, err) = p.communicate()
    return (p.returncode, out, err)

def prynt(*args, end='\n'):
    try:
        print(*[(arg.decode() 
                 if (type(arg) == bytes)
                 else arg)
                for arg in args], end=end)
    except:
        print(*args, end=end)

def size_human(value, integer=False):
    format_string = '{0:.0f}' if integer else '{0:.3f}'
    if value > 1024**4:
        return ('%s TB' % format_string).format(value / (1024**4))
    if value > 1024**3:
        return ('%s GB' % format_string).format(value / (1024**3))
    if value > 1024**2:
        return ('%s MB' % format_string).format(value / (1024**2))
    if value > 1024:
        return ('%s kB' % format_string).format(value / (1024))
    return '{0} B'.format(value)
"""
Vital classes
"""
class Parallelizer():
    # TODO terminate stuff
    def __init__(self, thread_count, data, function):
        self.thread_count = thread_count
        self.data = data
        self.function = function
        self.threads = []
        self.results = []

    def start(self):
        chunk_size = len(self.data) // self.thread_count
        if not chunk_size:
            chunk_size = 1
        indexed_data = list(enumerate(self.data, 1))
        data_chunks = [indexed_data[i:i+chunk_size] 
                       for i in range(0, len(indexed_data), chunk_size)]
        self.threads = [ParallelizerThread(data_chunks[i], self.function)
                        for i in range(len(data_chunks))]
        for t in self.threads:
            t.start()

    def waitfor(self):
        for t in self.threads:
            t.join()
            self.results += t.results



class ParallelizerThread(threading.Thread):
    # TODO terminate stuff...
    def __init__(self, data, function):
        threading.Thread.__init__(self)
        self.data = data
        self.function = function
        self.results = []

    def run(self):
        indices, samples = zip(*self.data)
        print('Running thread (samples %d through %d).' 
              % (indices[0], indices[-1]))
        self.results = self.function(indices, samples)


class Oracle(threading.Thread):
    """

    """
    def __init__(self, oracle_path, payloads):
        threading.Thread.__init__(self)
        self.oracle_path = oracle_path
        self.payloads = payloads
        self.matching = []

    def run(self):
        """
        sends payloads to given oracle, returns True if Oracle is happy
        The payload is base64-encoded
        """
        for byte_value, payload in self.payloads.items():
            #print('Oracle testing', byte_value)
            r, _, _ = run_command('%s %s' % (oracle_path, 
                                             base64.b64encode(payload).decode()))
            if r == 0:
                self.matching.append(byte_value)
                break

"""
Crypto functions
"""
def hex(data):
    return b''.join(b'%02x' % c for c in data)

def unhex(stream):
    return b''.join(b'%c' % int(stream[i:i+2], 16) 
                    for i in range(0, len(stream), 2))

def histogram(data):
    byte_counts = [0 for _ in range(256)]
    for byte in data:
        byte_counts[byte] += 1
    return byte_counts
    
def entropy(data):
    e = 0.0
    byte_counts = histogram(data)
    for count in byte_counts:
        if not count:
            continue
        p = count / len(data)
        e -= p* math.log(p, 256)
    return e

def entropy_chunks(data, chunksize):
    X = []
    Y = []
    for i in range(len(data)//chunksize + 1):
        X.append(i*chunksize)
        Y.append(entropy(data[i*chunksize:min(
            (i+1)*chunksize, len(data))]))
    return (X, Y)

def xor(data1, data2):
    return b''.join(b'%c' % (data1[i % len(data1)] ^ data2[i % len(data2)]) 
                    for i in range(max(len(data1), len(data2))))

def bruteforce_xor(data1, keys):
    for key in keys:
        yield xor(data1, key)

def dict_success(sample, min_word_match=1, min_word_len=1): # TODO or different constants?
    match_count = 0
    words = [w for w in re.sub(b'[^a-z]+', b' ', sample.lower()).split()
             if len(w) >= min_word_len]
    if not words:
        return 0
    found = [w for w in words if w in wordlist]
    if len(found) < min_word_match:
        return 0
    success = len(found) / len(words)
    return success

def hamming(data1, data2):
    result = 0
    for i in range(max(len(data1), len(data2))):
        c1 = data1[i] if i < len(data1) else 0
        c2 = data2[i] if i < len(data2) else 0
        xored = c1 ^ c2
        for bit in range(8):
            result += (xored >> bit) & 0x1
    return result
        
"""
Specific functions (e.g. print all ROTs or the valid one)
"""
def single_xor_print(data):
    results = bruteforce_xor(data, [b'%c' % i for i in range(256)])
    for byte, result in enumerate(results):
        if wordlist:
            if dict_success(result, 
                            min_word_match=3, 
                            min_word_len=3) > 0.2:
                print('0x%02x: ' % byte, end='')
                prynt(result)
        else:
            print(result)


"""
Cryptopals challenges
"""
def cp_1_4_function(indices, lines):
    for index, line in zip(indices, lines):
        unhexed = unhex(line)
        results = bruteforce_xor(unhexed, [b'%c' % i for i in range(256)])
        for byte, result in enumerate(results):
            if dict_success(result, min_word_match=3, min_word_len=3)>0.8:
                prynt('%d: 0x%02x:' % (index, byte), result)
    return []




"""
Load arguments
"""
method = ''
filename = ''
try:
    #filename = [a for a in sys.argv[1:] if not a.startswith('--')][0]
    debug_flag = '--debug' in sys.argv
    debug_flag = True # TODO delete after testing
    method = sys.argv[1][2:]
    if method == 'hex':
        filename = sys.argv[2]
    if method == 'unhex':
        payload = sys.argv[2]
    if method == 'entropy':
        filename = sys.argv[2]
        try:
            chunksize = int(sys.argv[3])
        except:
            chunksize = None

    if method == 'histogram':
        filename = sys.argv[2]
    if method == 'xorfiles':
        filename1 = sys.argv[2]
        filename2 = sys.argv[3]
    if method == 'brute-single-xor':
        filename = sys.argv[2]
        try:
            with open(sys.argv[3], 'rb') as f:
                wordlist = f.read().splitlines()
        except:
            wordlist = None
    if method == 'cp-1-4':
        filename = sys.argv[2]
        with open(sys.argv[3], 'rb') as f:
            wordlist = f.read().splitlines()
    if method == 'hamming':
        filename1 = sys.argv[2]
        filename2 = sys.argv[3]
    if method == 'break-xor':
        filename = sys.argv[2]
    if method == 'cbc-padding':
        filename = sys.argv[2]
        blocksize = int(sys.argv[3])
        oracle_path = sys.argv[4]
        with open(oracle_path, 'rb') as f:
            pass        
except:
    #print('[-] Usage: %s <filename>' % sys.argv[0])
    print('[-] Usage:')
    print('    %s --hex <file>' % sys.argv[0])
    print('    %s --unhex faceb00cdeadbeef' % sys.argv[0])
    print('    %s --entropy <file> [<chunksize>]' % sys.argv[0])
    print('    %s --histogram <file>' % sys.argv[0])
    print('    %s --xorfiles <file1> <file2>' % sys.argv[0])
    print('    %s --brute-single-xor <file> [<wordlist>]' % sys.argv[0])
    print('    %s --cp-1-4 <file> <wordlist>' % sys.argv[0])
    print('    %s --hamming <file1> <file2>' % sys.argv[0])
    print('    %s --break-xor <file>' % sys.argv[0])
    print('    %s --cbc-padding <file> <blocksize> <oracle_path>' % sys.argv[0])
    sys.exit(1)

# TODO --analyze
# TODO file, entropy, plaintext?
# TODO caesar, freqanal etc.

# TODO findmyhash

# TODO stream cipher reuse - 2 XORed with same key...
# ECB block reordering - we can use input to create separated desired data (like admin=1)
# ECB key reuse - add unencrypted stuff in the middle of stuff we can encrypt

# TODO hash extension
# https://blog.skullsecurity.org/2012/everything-you-need-to-know-about-hash-length-extension-attacks


if method == 'hex':
    with open(filename, 'rb') as f:
        data = f.read()
    prynt(hex(data))

if method == 'unhex':
    prynt(unhex(payload), end='')

if method == 'entropy':
    with open(filename, 'rb') as f:
        data = f.read()
    ent = entropy(data)
    print(ent)
    if chunksize:
        chunk_ent_X, chunk_ent_Y = entropy_chunks(data, chunksize) 
        plt.figure(figsize=(10, 5))
        plt.title('Entropy')
        plt.plot(chunk_ent_X, chunk_ent_Y, 
                 label='%s chunk entropy' % size_human(chunksize, 
                                                       integer=True))
        plt.plot(chunk_ent_X, [ent for _ in chunk_ent_X], alpha=0.4,
                 label='total entropy')
        plt.legend()
        plt.ylim(bottom=0.0, top=1.0)
        plt.show()
    
if method == 'histogram':
    with open(filename, 'rb') as f:
        data = f.read()
    histogram_colors = ['#005073', '#107dac', '#189ad3', '#71c7ec']
    plt.figure(figsize=(10, 5))
    plt.title('Byte histogram')
    plt.margins(x=0)
    # plot hist
    _, __, patches = plt.hist(bytearray(data), 
			      [x for x in range(256)])
    axes = plt.gca()
    # set hexadecimal ticks
    axes.get_xaxis().set_major_locator(ticker.MultipleLocator(16))
    axes.get_xaxis().set_major_formatter(plt.FuncFormatter(
	lambda value,tick_number: '0x%x' % int(value)))
    # color bars
    for i, p in enumerate(patches):
        plt.setp(p, 'facecolor', histogram_colors[
	    i % len(histogram_colors)])
    plt.show()
    
if method == 'xorfiles':
    with open(filename1, 'rb') as f:
        data1 = f.read()
    with open(filename2, 'rb') as f:
        data2 = f.read()
    prynt(xor(data1, data2), end='')

if method == 'brute-single-xor':
    with open(filename, 'rb') as f:
        data = f.read()
    single_xor_print(data)

if method == 'cp-1-4':
    with open(filename, 'rb') as f:
        lines = f.read().splitlines()
    """run XOR and dict analysis in parallel"""
    p = Parallelizer(8, lines, cp_1_4_function)
    p.start()
    p.waitfor()
    
if method == 'hamming':
    with open(filename1, 'rb') as f:
        data1 = f.read()
    with open(filename2, 'rb') as f:
        data2 = f.read()
    print(hamming(data1, data2))

if method == 'break-xor':
    with open(filename, 'rb') as f:
        data = f.read()
    # get normalized hamming for some keysizes, smallest should be the correct
    distances = {}
    for keysize in range(2, 40):
        tmp_distance = 0
        sample_count = 0
        for i in range(0, len(data)-keysize, keysize):
            sample1 = data[i:i+keysize]
            sample2 = data[i+keysize:i+2*keysize]
            sample_count += 1
            tmp_distance += hamming(sample1, sample2)
        distances[keysize] = tmp_distance / sample_count / keysize
    best = sorted(distances.items(), key=lambda x: x[1])
    print(best)
    # break into transposed(chunks of keysize)
    # run single-byte xor for them
    # print key
#############################################################
#############################################################
#############################################################

if method == 'cbc-padding':
    """
    CBC Padding Oracle Attack
    """
    """load data"""
    with open(filename, 'rb') as f:
        input_data = f.read()
    """create blocks of blocksize"""
    blocks = [input_data[i:i+blocksize] 
              for i in range(0, len(input_data), blocksize)]
    # TODO test if blocks have same len

    final_plaintexts = []
    """run through blocks in reverse order"""
    for block_index, block in enumerate(blocks[::-1]):
        block_plaintext = b''
        try:
            previous_block = blocks[::-1][block_index + 1]
            debug('Previous block:', 
                  ' '.join('%02x' % c for c in previous_block))
        except:
            previous_block = None
            debug('Previous block: None')
        
        debug('Actual block:  ', ' '.join('%02x' % c for c in block))
        
        """for each byte in block in reverse order"""
        for byte_index in range(blocksize-1, -1, -1):
            debug('Dealing with byte #%d (%02x)' 
                  % (byte_index, block[byte_index]))

            """prepare payloads for bruteforce"""
            valid_padding_byte = -1
            payloads = {}
            for bf_byte in range(256):
                """prepare fake previous block - start with zeros"""
                fake_prev = b'\x00' * (blocksize - len(block_plaintext) - 1)
                """add bruteforced byte"""
                fake_prev += b'%c' % bf_byte
                """
                then add values so xor with block gives expected padding values
                skipped on the first run
                """
                for byte_pos, plaintext_byte in enumerate(block_plaintext):
                    fake_prev += b'%c' % (plaintext_byte
                                          ^ (len(block_plaintext) + 1) # expected padding
                                          ^ (previous_block[blocksize-len(block_plaintext)+byte_pos]
                                             if previous_block
                                             else 0))
                """add the block and test it"""
                payloads[bf_byte] = fake_prev + block
            """bruteforce the padding"""
            #oracle_count = 1 # use this for debug
            oracle_count = 16 # use this for speed
            oracles = [Oracle(oracle_path, {k:v for k,v in payloads.items() 
                                            if (k // (len(payloads)/oracle_count) 
                                                == i)})
                       for i in range(oracle_count)]
            for oracle in oracles:
                oracle.start()
            for oracle in oracles:
                oracle.join()
                if oracle.matching:
                    valid_padding_byte = oracle.matching[0]
            
            '''
            #print('Will test payload:', payload)
            #print('Sending payload (%02x) to oracle...' % bf_byte)
            if cbc_padding_oracle(payload):
                valid_padding_byte = bf_byte
                break
            '''
            
            if valid_padding_byte == -1:
                debug('Failed to find valid padding byte!')

            debug('Found valid padding byte:', valid_padding_byte)
            """compute plaintext byte from padding byte"""
            block_plaintext = (b'%c' % ((len(block_plaintext) + 1) # expected padding
                                        ^ (previous_block[byte_index] 
                                           if previous_block 
                                           else 0) # byte of previous block
                                        ^ valid_padding_byte) # 
                               + block_plaintext)
            debug('New block plaintext:', block_plaintext)
        final_plaintexts.append(block_plaintext)
    try:
        print('Final plaintext:', (b''.join(final_plaintexts[::-1])).decode())
    except:
        print('Final plaintext:', b''.join(final_plaintexts[::-1]))

    #print(cbc_padding_oracle(base64.b64decode(b'4ET5cY0cfSnomIvhYPc0+Q==')))

